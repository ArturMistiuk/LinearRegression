{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8dba4106-035d-487f-a89f-f5a3e54c3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "83cb780e-3dc8-4f6f-822a-2797a6c9066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, w):\n",
    "    return np.dot(X, w)    # Матричне множення Х на вектор ваг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "de73d3fa-5320-4c6c-9a0d-eb672113e2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(X, y, w):\n",
    "    return np.square(h(X, w) - y).sum() / (2 * len(X))    # квадрат рiзницi мiж пронозами та фактичними значеннями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3cd36168-ef88-4ff0-a797-085b28501171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_step(X, y, w, learning_rate):\n",
    "    m = len(y)    # розмiр вибiрки\n",
    "    grad = (X.T @ (h(X, w) - y)) / m   #  формула градiєнта для лiнiйної регресiї\n",
    "    w -= learning_rate * grad    # оновлення ваг\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e4bd923e-50d4-46ae-842e-04f608ad9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, y, learning_rate, num_iter, eps):\n",
    "    ones = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((ones, X))\n",
    "\n",
    "    w = np.zeros(X.shape[1])    # вектор нульових ваг\n",
    "\n",
    "    loss = loss_function(X, y, w)\n",
    "    loss_history = [loss]    # icторiя втрат\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        w = gradient_step(X, y, w, learning_rate)\n",
    "\n",
    "        loss = loss_function(X, y, w)\n",
    "        if abs(loss - loss_history[-1]) < eps:\n",
    "            loss_history.append(loss)\n",
    "            break\n",
    "\n",
    "        loss_history.append(loss)\n",
    "\n",
    "    return w, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "40c2d2f3-ad38-4dbf-b3dd-3d2369d228d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent - w: [4766729.23596627  821968.67551979  300259.83239246  696447.05416246]\n",
      "Analytical Solution - Optimal w: [4766729.24770642  821968.58935343  300259.16468032  696447.75898579]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"Housing.csv\")\n",
    "norm = df.copy()    # датафрейм для нормалiзацiї\n",
    "columns = ['price', 'area', 'bedrooms', 'bathrooms']\n",
    "for column in columns[1:]:\n",
    "    norm[column] = (df[column] - df[column].mean()) / df[column].std()    # нормалiзацiя(значення - середнє / стандартне вiдхилення) \n",
    "\n",
    "\n",
    "X = norm[['area', 'bedrooms', 'bathrooms']].values    # матриця нормалiзованних факторiв\n",
    "y = norm['price'].values\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_iter = 100000    # максимум в iтерацiях \n",
    "eps = 1e-12    # рiзниця в значеннях \n",
    "\n",
    "# формула градiєнту\n",
    "w_gradient, loss_history = gradient(X, y, learning_rate, num_iter, eps)\n",
    "print('Gradient Descent - w:', w_gradient)\n",
    "\n",
    "# аналiтична формула\n",
    "ones = np.ones((X.shape[0], 1))\n",
    "X = np.hstack((ones, X))\n",
    "w_analytical = np.linalg.pinv(X.T @ X) @ X.T @ y   \n",
    "print('Analytical Solution - Optimal w:', w_analytical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
